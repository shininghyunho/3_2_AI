forest.results
forest.results$Fold01
forest.results$Fold02
forest.results$Fold02[0]
forest.results$Fold02[1]
############### k-fold cross validation - decision tree
library(caret)
folds <- createFolds(wordmatrix$cat, k = 10)
forest.results <- lapply(folds, function(x) {
forest.train <- word[x,]
forest.test <- word[-x,]
forest.model <- randomForest(cat~., data = forest.train)
forest.predict <- predict(forest.model, forest.test)
forest.actual <- forest.test$cat
forest.predicval <- confusionMatrix(forest.predict, forest.test$cat)
return (forest.predicval)
})
mean(unlist(forest.results))
forest.results
## k-fold svm
library(caret)
folds <- createFolds(wordmatrix$cat, k = 10)
svm.results <- lapply(folds, function(x) {
svm.train <- word[x,]
svm.test <- word[-x,]
svm.model = svm(cat ~ ., data=svm.train, type='C-classification',
kernel='linear', cost=100000, scale=FALSE)
svm.predict <- predict(svm.model, svm.test)
svm.actual <- svm.test$cat
svm.predicval <- confusionMatrix(svm.predict, svm.test$cat)$overall[1]
return (svm.predicval)
})
mean(unlist(svm.results))
## k-fold svm
library(caret)
folds <- createFolds(wordmatrix$cat, k = 10)
svm.results <- lapply(folds, function(x) {
svm.train <- word[x,]
svm.test <- word[-x,]
svm.model = svm(cat ~ ., data=svm.train, type='C-classification',
kernel='linear', cost=100000, scale=FALSE)
svm.predict <- predict(svm.model, svm.test)
svm.actual <- svm.test$cat
svm.predicval <- confusionMatrix(svm.predict, svm.test$cat)
return (svm.predicval)
})
mean(unlist(svm.results))
############################ Neural Network
# train whole data
library("neuralnet")
svm.results
unlist(svm.results)
mean(unlist(svm.results)$Accuracy)
## k-fold svm
library(caret)
folds <- createFolds(wordmatrix$cat, k = 10)
svm.results <- lapply(folds, function(x) {
svm.train <- word[x,]
svm.test <- word[-x,]
svm.model = svm(cat ~ ., data=svm.train, type='C-classification',
kernel='linear', cost=100000, scale=FALSE)
svm.predict <- predict(svm.model, svm.test)
svm.actual <- svm.test$cat
svm.predicval <- confusionMatrix(svm.predict, svm.test$cat)$overall[1]
return (svm.predicval)
})
unlist(svm.results)
mean(unlist(svm.results))
svm.model = svm(cat ~ ., data=word,cost=10000, scale=FALSE)
svm.model
#svm.model <- svm(cat ~., data=word, cost=100, gamma =1)
svm_pred_train <- predict(svm.model, word)
tab=table(word$cat, svm_pred_train)
tab
error_rate = 1-sum(diag(tab)/sum(tab))
# accuracy
(1-error_rate)*100
############### k-fold cross validation - decision tree
library(caret)
## SVM -2
library(e1071)
svm.model = svm(cat ~ ., data=word,cost=10000, scale=FALSE)
svm.model
svm_pred_train <- predict(svm.model, word)
tab=table(word$cat, svm_pred_train)
tab
error_rate = 1-sum(diag(tab)/sum(tab))
# accuracy
(1-error_rate)*100
svm.model = svm(cat ~ ., data=word,cost=1000000, scale=FALSE)
svm.model
svm_pred_train <- predict(svm.model, word)
tab=table(word$cat, svm_pred_train)
tab
error_rate = 1-sum(diag(tab)/sum(tab))
# accuracy
(1-error_rate)*100
svm.model = svm(cat ~ ., data=word,cost=1000000, gamma =10, scale=FALSE)
svm.model
svm_pred_train <- predict(svm.model, word)
tab=table(word$cat, svm_pred_train)
tab
error_rate = 1-sum(diag(tab)/sum(tab))
# accuracy
(1-error_rate)*100
## SVM -2
library(e1071)
svm.model = svm(cat ~ ., data=word,cost=1000000, gamma =100, scale=FALSE)
svm.model
svm_pred_train <- predict(svm.model, word)
tab=table(word$cat, svm_pred_train)
tab
error_rate = 1-sum(diag(tab)/sum(tab))
# accuracy
(1-error_rate)*100
svm.model = svm(cat ~ ., data=word,cost=1000000, gamma =1000, scale=FALSE)
svm.model
svm_pred_train <- predict(svm.model, word)
tab=table(word$cat, svm_pred_train)
tab
error_rate = 1-sum(diag(tab)/sum(tab))
# accuracy
(1-error_rate)*100
svm.model = svm(cat ~ ., data=word,cost=1000000, gamma =1, scale=FALSE)
svm.model
svm_pred_train <- predict(svm.model, word)
tab=table(word$cat, svm_pred_train)
tab
error_rate = 1-sum(diag(tab)/sum(tab))
# accuracy
(1-error_rate)*100
## SVM -2
library(e1071)
svm.model = svm(cat ~ ., data=word,cost=1000000, gamma =1, scale=FALSE)
svm.model
svm_pred_train <- predict(svm.model, word)
tab=table(word$cat, svm_pred_train)
tab
error_rate = 1-sum(diag(tab)/sum(tab))
# accuracy
(1-error_rate)*100
svm.model = svm(cat ~ ., data=word,cost=1000000, gamma =10000, scale=FALSE)
svm.model
svm_pred_train <- predict(svm.model, word)
tab=table(word$cat, svm_pred_train)
tab
error_rate = 1-sum(diag(tab)/sum(tab))
# accuracy
(1-error_rate)*100
svm.model = svm(cat ~ ., data=word,cost=100, gamma =10000, scale=FALSE)
svm.model
svm_pred_train <- predict(svm.model, word)
tab=table(word$cat, svm_pred_train)
tab
error_rate = 1-sum(diag(tab)/sum(tab))
# accuracy
(1-error_rate)*100
svm.model = svm(cat ~ ., data=word,cost=1000, gamma =100, scale=FALSE)
svm.model
svm_pred_train <- predict(svm.model, word)
tab=table(word$cat, svm_pred_train)
tab
error_rate = 1-sum(diag(tab)/sum(tab))
# accuracy
(1-error_rate)*100
folds <- createFolds(wordmatrix$cat, k = 10)
svm.results <- lapply(folds, function(x) {
svm.train <- word[x,]
svm.test <- word[-x,]
svm.model = svm(cat ~ ., data=svm.train,scale=FALSE)
svm.predict <- predict(svm.model, svm.test)
svm.actual <- svm.test$cat
svm.predicval <- confusionMatrix(svm.predict, svm.test$cat)$overall[1]
return (svm.predicval)
})
mean(unlist(svm.results))
svm.actual <- svm.test$cat
svm.results <- lapply(folds, function(x) {
svm.train <- word[x,]
svm.test <- word[-x,]
svm.model = svm(cat ~ ., data=svm.train,scale=FALSE)
svm.predict <- predict(svm.model, svm.test)
svm.actual <- svm.test$cat
svm.predicval <- confusionMatrix(svm.predict, svm.test$cat)
return (svm.predicval)
})
## k-fold svm
library(caret)
folds <- createFolds(wordmatrix$cat, k = 2)
svm.results <- lapply(folds, function(x) {
svm.train <- word[x,]
svm.test <- word[-x,]
svm.model = svm(cat ~ ., data=svm.train,scale=FALSE)
svm.predict <- predict(svm.model, svm.test)
svm.actual <- svm.test$cat
svm.predicval <- confusionMatrix(svm.predict, svm.test$cat)
return (svm.predicval)
})
mean(unlist(svm.results))
############################ Neural Network
# train whole data
library("neuralnet")
folds <- createFolds(wordmatrix$cat, k = 2)
svm.results <- lapply(folds, function(x) {
svm.train <- word[x,]
svm.test <- word[-x,]
svm.model = svm(cat ~ ., data=svm.train,scale=FALSE)
svm.predict <- predict(svm.model, svm.test)
svm.actual <- svm.test$cat
svm.predicval <- confusionMatrix(svm.predict, svm.test$cat)$overall[1]
return (svm.predicval)
})
mean(unlist(svm.results))
folds <- createFolds(wordmatrix$cat, k = 3)
svm.results <- lapply(folds, function(x) {
svm.train <- word[x,]
svm.test <- word[-x,]
svm.model = svm(cat ~ ., data=svm.train,scale=FALSE)
svm.predict <- predict(svm.model, svm.test)
svm.actual <- svm.test$cat
svm.predicval <- confusionMatrix(svm.predict, svm.test$cat)$overall[1]
return (svm.predicval)
})
mean(unlist(svm.results))
############### k-fold cross validation - decision tree
library(caret)
folds <- createFolds(wordmatrix$cat, k = 3)
forest.results <- lapply(folds, function(x) {
forest.train <- word[x,]
forest.test <- word[-x,]
forest.model <- randomForest(cat~., data = forest.train)
forest.predict <- predict(forest.model, forest.test)
forest.actual <- forest.test$cat
forest.predicval <- confusionMatrix(forest.predict, forest.test$cat)
return (forest.predicval)
})
mean(unlist(forest.results))
forest.model <- randomForest(cat~., data = forest.train)
forest.predict <- predict(forest.model, forest.test)
forest.actual <- forest.test$cat
forest.results <- lapply(folds, function(x) {
forest.train <- word[x,]
forest.test <- word[-x,]
forest.model <- randomForest(cat~., data = forest.train)
forest.predict <- predict(forest.model, forest.test)
forest.actual <- forest.test$cat
forest.predicval <- confusionMatrix(forest.predict, forest.test$cat)$overall[1]
return (forest.predicval)
})
mean(unlist(forest.results))
folds <- createFolds(wordmatrix$cat, k = 5)
forest.results <- lapply(folds, function(x) {
forest.train <- word[x,]
forest.test <- word[-x,]
forest.model <- randomForest(cat~., data = forest.train)
forest.predict <- predict(forest.model, forest.test)
forest.actual <- forest.test$cat
forest.predicval <- confusionMatrix(forest.predict, forest.test$cat)$overall[1]
return (forest.predicval)
})
mean(unlist(forest.results))
folds <- createFolds(wordmatrix$cat, k = 2)
svm.results <- lapply(folds, function(x) {
svm.train <- word[x,]
svm.test <- word[-x,]
svm.model = svm(cat ~ ., data=svm.train,scale=FALSE)
svm.predict <- predict(svm.model, svm.test)
svm.actual <- svm.test$cat
svm.predicval <- confusionMatrix(svm.predict, svm.test$cat)$overall[1]
return (svm.predicval)
})
mean(unlist(svm.results))
############### k-fold cross validation - decision tree
library(caret)
folds <- createFolds(wordmatrix$cat, k = 2)
forest.results <- lapply(folds, function(x) {
forest.train <- word[x,]
forest.test <- word[-x,]
forest.model <- randomForest(cat~., data = forest.train)
forest.predict <- predict(forest.model, forest.test)
forest.actual <- forest.test$cat
forest.predicval <- confusionMatrix(forest.predict, forest.test$cat)$overall[1]
return (forest.predicval)
})
mean(unlist(forest.results))
folds <- createFolds(wordmatrix$cat, k = 1)
svm.results <- lapply(folds, function(x) {
svm.train <- word[x,]
svm.test <- word[-x,]
svm.model = svm(cat ~ ., data=svm.train,kernel='linear',scale=FALSE)
svm.predict <- predict(svm.model, svm.test)
svm.actual <- svm.test$cat
svm.predicval <- confusionMatrix(svm.predict, svm.test$cat)$overall[1]
return (svm.predicval)
})
mean(unlist(svm.results))
## k-fold svm radial
library(caret)
folds <- createFolds(wordmatrix$cat, k = 2)
svm.results <- lapply(folds, function(x) {
svm.train <- word[x,]
svm.test <- word[-x,]
svm.model = svm(cat ~ ., data=svm.train,kernel='radial',scale=FALSE)
svm.predict <- predict(svm.model, svm.test)
svm.actual <- svm.test$cat
svm.predicval <- confusionMatrix(svm.predict, svm.test$cat)$overall[1]
return (svm.predicval)
})
mean(unlist(svm.results))
############### k-fold cross validation - decision tree
library(caret)
folds <- createFolds(wordmatrix$cat, k = 100)
forest.results <- lapply(folds, function(x) {
forest.train <- word[x,]
forest.test <- word[-x,]
forest.model <- randomForest(cat~., data = forest.train)
forest.predict <- predict(forest.model, forest.test)
forest.actual <- forest.test$cat
forest.predicval <- confusionMatrix(forest.predict, forest.test$cat)$overall[1]
return (forest.predicval)
})
mean(unlist(forest.results))
## k-fold svm linear
library(caret)
folds <- createFolds(wordmatrix$cat, k = 2)
svm.results <- lapply(folds, function(x) {
svm.train <- word[x,]
svm.test <- word[-x,]
svm.model = svm(cat ~ ., data=svm.train,kernel='linear',scale=FALSE)
svm.predict <- predict(svm.model, svm.test)
svm.actual <- svm.test$cat
svm.predicval <- confusionMatrix(svm.predict, svm.test$cat)$overall[1]
return (svm.predicval)
})
mean(unlist(svm.results))
## k-fold svm radial
library(caret)
folds <- createFolds(wordmatrix$cat, k = 2)
svm.results <- lapply(folds, function(x) {
svm.train <- word[x,]
svm.test <- word[-x,]
svm.model = svm(cat ~ ., data=svm.train,kernel='radial',scale=FALSE)
svm.predict <- predict(svm.model, svm.test)
svm.actual <- svm.test$cat
svm.predicval <- confusionMatrix(svm.predict, svm.test$cat)$overall[1]
return (svm.predicval)
})
mean(unlist(svm.results))
############################ Neural Network
# train whole data
library("neuralnet")
set.seed(2019)
i = sample(1:nrow(word), round(nrow(word)*0.7))
word.train = word[i,]
plot(c(0,0),c(1,0),c(0,1),c(1,1))
plot((0,0),(1,0),(0,1),(1,1))
plot(0,0)
plot(1,0)
plot(c(0,0),c(1,1))
plot(c(0,0),c(1,1))
plot(1,0)
plot(c(0,1),c(1,0))
plot(c(1,0),c(0,1))
plot(c(1,0),c(0,1))
plot(1,1)
plot(x,y, main="PLOT",sub = "type=p",xlab="x-lab",ylab="y-lab",type="p")
x=c(0,1)
y=c(0,1)
plot(x,y, main="PLOT",sub = "type=p",xlab="x-lab",ylab="y-lab",type="p")
x=c(0,1,1)
y=c(0,1)
plot(x,y, main="PLOT",sub = "type=p",xlab="x-lab",ylab="y-lab",type="p")
y=c(0,1,1)
plot(x,y, main="PLOT",sub = "type=p",xlab="x-lab",ylab="y-lab",type="p")
x=c(0,1,2)
y=c(0,1,2)
plot(x,y, main="PLOT",sub = "type=p",xlab="x-lab",ylab="y-lab",type="p")
x=c(0,0,1,1)
y=c(0,1,0,1)
plot(x,y, main="PLOT",sub = "type=p",xlab="x-lab",ylab="y-lab",type="p")
plot(x,y, main="PLOT",sub = "type=p",xlab="x-lab",ylab="y-lab",type="p",cex=2)
plot(x,y, main="PLOT",sub = "type=p",xlab="x-lab",ylab="y-lab",type="p",pch=1,cex=2)
plot(x,y, main="PLOT",sub = "type=p",xlab="x-lab",ylab="y-lab",type="p",pch=2,cex=2)
plot(x,y, main="PLOT",sub = "type=p",xlab="x-lab",ylab="y-lab",type="p",pch=3,cex=2)
plot(x,y, main="PLOT",sub = "type=p",xlab="x-lab",ylab="y-lab",type="p",pch=4,cex=2)
plot(x,y, main="PLOT",sub = "type=p",xlab="x-lab",ylab="y-lab",type="p",pch=5,cex=2)
plot(x,y, main="PLOT",sub = "type=p",xlab="x-lab",ylab="y-lab",type="p",pch=6,cex=2)
plot(x,y, main="PLOT",sub = "type=p",xlab="x-lab",ylab="y-lab",type="p",pch=1,cex=2)
plot(x,y, main="PLOT",sub = "type=p",xlab="x-lab",ylab="y-lab",type="p",pch=1,cex=3)
plot(x,y, main="PLOT",sub = "type=p",xlab="x-lab",ylab="y-lab",type="p",pch=1,cex=2)
lines(c(-1,0.5),c(0.5,-1))
lines(c(-1,1.5),c(1.5,-1))
lines(c(-1,1.5),c(1.5,-1),lty=1)
lines(c(-1,1.5),c(1.5,-1),lty=2)
lines(c(-1,1.5),c(1.5,-1),lty=3)
lines(c(-1,1.5),c(1.5,-1),lty=6)
lines(c(-1,1.5),c(1.5,-1),lty=1)
lines(c(-1,1.5),c(1.5,-1),col=red)
lines(c(-1,1.5),c(1.5,-1),col=r)
lines(c(-1,1.5),c(1.5,-1),col="r")
lines(c(-1,1.5),c(1.5,-1),col="red")
lines(c(-1,1.8),c(1.8,-1),col="red")
plot(x,y, main="PLOT",sub = "type=p",xlab="x-lab",ylab="y-lab",type="p",pch=1,cex=2)
lines(c(-1,1.8),c(1.8,-1),col="red")
clear
clear()
plot.default()
abline(h = 0:1, v = 0:1, col = "Gray", lty=3)
abline(h = 0:1, v = 0:1, col = "Gray", lty=1)
abline(h = 0:1, v = 0:1, col = "Gray", lty=2)
plot(x,y, main="PLOT",sub = "type=p",xlim=c(-0.5,1.5),ylim=c(-0.5,1.5),xlab="x-lab",ylab="y-lab",type="p",pch=1,cex=2)
lines(c(-1,1.5),c(1.5,-1),col="red")
abline(h = -0.5:1.5, v = -0.5:1.5, col = "Gray", lty=3)
abline(h = -0:1.5, v = -0:1.5, col = "Gray", lty=3)
abline(h = 0:1.5, v = 0:1.5, col = "Gray", lty=3)
points(x=c(1),y=c(1),col="red")
points(x=c(1),y=c(1),col="red",cex=2)
x=c(0,0,1,1)
y=c(0,1,0,1)
plot(x,y, main="PLOT",sub = "type=p",xlim=c(-0.5,1.5),ylim=c(-0.5,1.5),xlab="x-lab",ylab="y-lab",type="p",pch=1,cex=2)
abline(h = 0:1.5, v = 0:1.5, col = "Gray", lty=3)
points(x=c(1),y=c(1),col="red",cex=2)
lines(c(-1,1.5),c(1.5,-1),col="red")
setwd("C:\\Users\\hyunho\\Shiny\\study\\3-2\\univ_class\\Ai\\과제\\#3\\xor3")
input<-read.csv("input.csv",header=F)
weight<-read.csv("w_layer.csv",header=F)
bias<-read.csv("bias.csv",header=F)
err<-read.csv("err.csv",header=F)
data<-cbind(input,weight,bias)
data<-data[-c(5,12,16)]
data
names(data)<-(c("in00","in10","in01","in11","w000","w100","w010","w110","w001","w101","b00","b10","b01"))
slope00<-c(0)
intercept00<-c(0)
data<-cbind(data,slope00,intercept00)
data=transform(data,slope00=-w000/w100)
data=transform(data,intercept00=-b00/w100)
slope10<-c(0)
intercept10<-c(0)
data<-cbind(data,slope10,intercept10)
data=transform(data,slope10=-w010/w110)
data=transform(data,intercept10=-b10/w110)
slope01<-c(0)
intercept01<-c(0)
data<-cbind(data,slope01,intercept01)
data=transform(data,slope01=-w001/w101)
data=transform(data,intercept01=-b01/w101)
data
x=c(0,0,1,1)
y=c(0,1,0,1)
# node00 with node10 whole input
for(i in 1:nrow(data)-3){
if(i%%4==1){
plot(c(5),c(5),main="PLOT",sub = "type=p",xlim=c(-2.5,3.5),ylim=c(-2.5,3.5),xlab="x-lab",ylab="y-lab");
abline(h = 0:1.5, v = 0:1.5, col = "Gray", lty=3);
points(x=data$in01[i],y=data$in11[i],col="black",cex=2)
points(x=data$in01[i+1],y=data$in11[i+1],col="green",cex=2)
points(x=data$in01[i+2],y=data$in11[i+2],col="green",cex=2)
points(x=data$in01[i+3],y=data$in11[i+3],col="black",cex=2)
abline(a=data$intercept01[i],b=data$slope01[i],col="red")
Sys.sleep(0.1)
}
}
# node00 with node10 whole input
for(i in 1:nrow(data)-3){
if(i%%4==1){
plot(c(5),c(5),main="PLOT",sub = "type=p",xlim=c(-2.5,3.5),ylim=c(-2.5,3.5),xlab="x-lab",ylab="y-lab");
abline(h = 0:1.5, v = 0:1.5, col = "Gray", lty=3);
points(x=data$in01[i],y=data$in11[i],col="black",cex=2)
points(x=data$in01[i+1],y=data$in11[i+1],col="green",cex=2)
points(x=data$in01[i+2],y=data$in11[i+2],col="green",cex=2)
points(x=data$in01[i+3],y=data$in11[i+3],col="black",cex=2)
abline(a=data$intercept01[i],b=data$slope01[i],col="red")
Sys.sleep(0.1)
}
}
# node00 with node10 whole input
for(i in 1:nrow(data)-3){
if(i%%4==1){
plot(c(5),c(5),main="PLOT",sub = "type=p",xlim=c(-2.5,3.5),ylim=c(-2.5,3.5),xlab="x-lab",ylab="y-lab");
abline(h = 0:1.5, v = 0:1.5, col = "Gray", lty=3);
points(x=data$in01[i],y=data$in11[i],col="black",cex=2)
points(x=data$in01[i+1],y=data$in11[i+1],col="green",cex=2)
points(x=data$in01[i+2],y=data$in11[i+2],col="green",cex=2)
points(x=data$in01[i+3],y=data$in11[i+3],col="black",cex=2)
abline(a=data$intercept01[i],b=data$slope01[i],col="red")
Sys.sleep(0.1)
}
}
# node10 whole input
for(i in 1:nrow(data)){
plot(x,y, main="PLOT",sub = "type=p",xlim=c(-2.5,3.5),ylim=c(-2.5,3.5),xlab="x-lab",ylab="y-lab",type="p",pch=1,cex=2)
abline(h = 0:1.5, v = 0:1.5, col = "Gray", lty=3)
points(x=c(1),y=c(0),col="green",cex=2)
points(x=c(0),y=c(1),col="green",cex=2)
if(i%%4==1){
abline(a=data$intercept10[i],b=data$slope10[i],col="blue")
Sys.sleep(0.1)
}
}
# node00 with node10 whole input
for(i in 1:nrow(data)){
plot(x,y, main="PLOT",sub = "type=p",xlim=c(-2.5,3.5),ylim=c(-2.5,3.5),xlab="x-lab",ylab="y-lab",type="p",pch=1,cex=2)
abline(h = 0:1.5, v = 0:1.5, col = "Gray", lty=3)
points(x=c(1),y=c(0),col="green",cex=2)
points(x=c(0),y=c(1),col="green",cex=2)
if(i%%4==1){
abline(a=data$intercept00[i],b=data$slope00[i],col="red")
abline(a=data$intercept10[i],b=data$slope10[i],col="blue")
Sys.sleep(0.1)
}
}
